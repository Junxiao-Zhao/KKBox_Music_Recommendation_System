{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "MSNO done.\n",
      "Song_id done.\n",
      "Source information done.\n",
      "Members information done.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "## load the data\n",
    "members = pd.read_csv('../source_data/members.csv')\n",
    "songs = pd.read_csv('../source_data/songs.csv')\n",
    "songs_extra = pd.read_csv('../source_data/song_extra_info.csv')\n",
    "train = pd.read_csv('../source_data/train.csv')\n",
    "test = pd.read_csv('../source_data/test.csv')\n",
    "\n",
    "\n",
    "song_id_set = set(train['song_id']._append(test['song_id']))\n",
    "\n",
    "songs['appeared'] = songs['song_id'].apply(lambda x: True if x in song_id_set else False)\n",
    "songs = songs[songs.appeared]\n",
    "songs.drop('appeared', axis=1, inplace=True)\n",
    "\n",
    "songs_extra['appeared'] = songs_extra['song_id'].apply(lambda x: True if x in song_id_set else False)\n",
    "songs_extra = songs_extra[songs_extra.appeared]\n",
    "songs_extra.drop('appeared', axis=1, inplace=True)\n",
    "\n",
    "msno_set = set(train['msno']._append(test['msno']))\n",
    "\n",
    "members['appeared'] = members['msno'].apply(lambda x: True if x in msno_set else False)\n",
    "members = members[members.appeared]\n",
    "members.drop('appeared', axis=1, inplace=True)\n",
    "\n",
    "print('Data loaded.')\n",
    "\n",
    "\n",
    "## preprocess msno and song_id\n",
    "msno_encoder = LabelEncoder()\n",
    "msno_encoder.fit(members['msno'].values)\n",
    "members['msno'] = msno_encoder.transform(members['msno'])\n",
    "train['msno'] = msno_encoder.transform(train['msno'])\n",
    "test['msno'] = msno_encoder.transform(test['msno'])\n",
    "\n",
    "print('MSNO done.')\n",
    "\n",
    "song_id_encoder = LabelEncoder()\n",
    "song_id_encoder.fit(train['song_id']._append(test['song_id']))\n",
    "songs['song_id'] = song_id_encoder.transform(songs['song_id'])\n",
    "songs_extra['song_id'] = song_id_encoder.transform(songs_extra['song_id'])\n",
    "train['song_id'] = song_id_encoder.transform(train['song_id'])\n",
    "test['song_id'] = song_id_encoder.transform(test['song_id'])\n",
    "\n",
    "print('Song_id done.')\n",
    "\n",
    "## preprocess the features in train.csv & test.csv\n",
    "columns = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "for column in columns:\n",
    "    column_encoder = LabelEncoder()\n",
    "    column_encoder.fit(train[column]._append(test[column]))\n",
    "    train[column] = column_encoder.transform(train[column])\n",
    "    test[column] = column_encoder.transform(test[column])\n",
    "\n",
    "print('Source information done.')\n",
    "\n",
    "\n",
    "## preprocess the features in members.csv\n",
    "columns = ['city', 'gender', 'registered_via']\n",
    "for column in columns:\n",
    "    column_encoder = LabelEncoder()\n",
    "    column_encoder.fit(members[column])\n",
    "    members[column] = column_encoder.transform(members[column])\n",
    "\n",
    "members['registration_init_time'] = members['registration_init_time'].apply(lambda x: \\\n",
    "        time.mktime(time.strptime(str(x),'%Y%m%d')))\n",
    "members['expiration_date'] = members['expiration_date'].apply(lambda x: \\\n",
    "        time.mktime(time.strptime(str(x),'%Y%m%d')))\n",
    "\n",
    "print('Members information done.')\n",
    "\n",
    "## preprocess the features in songs.csv\n",
    "genre_id = np.zeros((len(songs), 4))\n",
    "for i in range(len(songs)):\n",
    "    if not isinstance(songs['genre_ids'].values[i], str):\n",
    "        continue\n",
    "    ids = str(songs['genre_ids'].values[i]).split('|')\n",
    "    if len(ids) > 2:\n",
    "        genre_id[i, 0] = int(ids[0])\n",
    "        genre_id[i, 1] = int(ids[1])\n",
    "        genre_id[i, 2] = int(ids[2])\n",
    "    elif len(ids) > 1:\n",
    "        genre_id[i, 0] = int(ids[0])\n",
    "        genre_id[i, 1] = int(ids[1])\n",
    "    elif len(ids) == 1:\n",
    "        genre_id[i, 0] = int(ids[0])\n",
    "    genre_id[i, 3] = len(ids)\n",
    "songs['first_genre_id'] = genre_id[:, 0]\n",
    "songs['second_genre_id'] = genre_id[:, 1]\n",
    "songs['third_genre_id'] = genre_id[:, 2]\n",
    "songs['genre_id_cnt'] = genre_id[:, 3]\n",
    "\n",
    "genre_encoder = LabelEncoder()\n",
    "genre_encoder.fit((songs.first_genre_id._append(songs.second_genre_id))._append(songs.third_genre_id))\n",
    "songs['first_genre_id'] = genre_encoder.transform(songs['first_genre_id'])\n",
    "songs['second_genre_id'] = genre_encoder.transform(songs['second_genre_id'])\n",
    "songs['third_genre_id'] = genre_encoder.transform(songs['third_genre_id'])\n",
    "songs.drop('genre_ids', axis=1, inplace=True)\n",
    "\n",
    "def artist_count(x):\n",
    "    return x.count('and') + x.count(',') + x.count(' feat') + x.count('&') + 1\n",
    "\n",
    "songs['artist_cnt'] = songs['artist_name'].apply(artist_count).astype(np.int8)\n",
    "\n",
    "def get_count(x):\n",
    "    try:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "songs['lyricist_cnt'] = songs['lyricist'].apply(get_count).astype(np.int8)\n",
    "songs['composer_cnt'] = songs['composer'].apply(get_count).astype(np.int8)\n",
    "\n",
    "songs['is_featured'] = songs['artist_name'].apply(lambda x: 1 if ' feat' \\\n",
    "        in str(x) else 0).astype(np.int8)\n",
    "\n",
    "def get_first_artist(x):\n",
    "    if x.count('and') > 0:\n",
    "        x = x.split('and')[0]\n",
    "    if x.count(',') > 0:\n",
    "        x = x.split(',')[0]\n",
    "    if x.count(' feat') > 0:\n",
    "        x = x.split(' feat')[0]\n",
    "    if x.count('&') > 0:\n",
    "        x = x.split('&')[0]\n",
    "    return x.strip()\n",
    "\n",
    "songs['artist_name'] = songs['artist_name'].apply(get_first_artist)\n",
    "    \n",
    "def get_first_term(x):\n",
    "    try:\n",
    "        if x.count('|') > 0:\n",
    "            x = x.split('|')[0]\n",
    "        if x.count('/') > 0:\n",
    "            x = x.split('/')[0]\n",
    "        if x.count('\\\\') > 0:\n",
    "            x = x.split('\\\\')[0]\n",
    "        if x.count(';') > 0:\n",
    "            x = x.split(';')[0]\n",
    "        return x.strip()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "songs['lyricist'] = songs['lyricist'].apply(get_first_term)\n",
    "songs['composer'] = songs['composer'].apply(get_first_term)        \n",
    "\n",
    "songs['language'] = songs['language'].fillna(-1)\n",
    "columns = ['artist_name', 'lyricist', 'composer', 'language']\n",
    "for column in columns:\n",
    "    column_encoder = LabelEncoder()\n",
    "    column_encoder.fit(songs[column])\n",
    "    songs[column] = column_encoder.transform(songs[column])\n",
    "\n",
    "\n",
    "## save files\n",
    "members.to_csv('../temporal_data/members_id.csv', index=False)\n",
    "songs.to_csv('../temporal_data/songs_id.csv', index=False)\n",
    "songs_extra.to_csv('../temporal_data/songs_extra_id.csv', index=False)\n",
    "train.to_csv('../temporal_data/train_id.csv', index=False)\n",
    "test.to_csv('../temporal_data/test_id.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnt_log_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../temporal_data/train_id.csv')\n",
    "test = pd.read_csv('../temporal_data/test_id.csv')\n",
    "member = pd.read_csv('../temporal_data/members_id.csv')\n",
    "song_origin = pd.read_csv('../temporal_data/songs_id.csv')\n",
    "song_extra = pd.read_csv('../temporal_data/songs_extra_id.csv')\n",
    "\n",
    "song = pd.DataFrame({'song_id': range(max(train.song_id.max(), test.song_id.max())+1)})\n",
    "song = song.merge(song_origin, on='song_id', how='left')\n",
    "song = song.merge(song_extra, on='song_id', how='left')\n",
    "\n",
    "data = train[['msno', 'song_id']]._append(test[['msno', 'song_id']])\n",
    "\n",
    "## member_cnt\n",
    "mem_rec_cnt = data.groupby(by='msno').count()['song_id'].to_dict()\n",
    "member['msno_rec_cnt'] = member['msno'].apply(lambda x: mem_rec_cnt[x])\n",
    "\n",
    "member['bd'] = member['bd'].apply(lambda x: np.nan if x <= 0 or x >= 75 else x)\n",
    "\n",
    "## song_cnt\n",
    "artist_song_cnt = song.groupby(by='artist_name').count()['song_id'].to_dict()\n",
    "song['artist_song_cnt'] = song['artist_name'].apply(lambda x: artist_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "composer_song_cnt = song.groupby(by='composer').count()['song_id'].to_dict()\n",
    "composer_song_cnt[0] = np.nan\n",
    "song['composer_song_cnt'] = song['composer'].apply(lambda x: composer_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "lyricist_song_cnt = song.groupby(by='lyricist').count()['song_id'].to_dict()\n",
    "lyricist_song_cnt[0] = np.nan\n",
    "song['lyricist_song_cnt'] = song['lyricist'].apply(lambda x: lyricist_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "genre_song_cnt = song.groupby(by='first_genre_id').count()['song_id'].to_dict()\n",
    "genre_song_cnt[0] = np.nan\n",
    "song['genre_song_cnt'] = song['first_genre_id'].apply(lambda x: genre_song_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "data = data.merge(song, on='song_id', how='left')\n",
    "\n",
    "song_rec_cnt = data.groupby(by='song_id').count()['msno'].to_dict()\n",
    "song['song_rec_cnt'] = song['song_id'].apply(lambda x: song_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "artist_rec_cnt = data.groupby(by='artist_name').count()['msno'].to_dict()\n",
    "song['artist_rec_cnt'] = song['artist_name'].apply(lambda x: artist_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "composer_rec_cnt = data.groupby(by='composer').count()['msno'].to_dict()\n",
    "composer_rec_cnt[0] = np.nan\n",
    "song['composer_rec_cnt'] = song['composer'].apply(lambda x: composer_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "lyricist_rec_cnt = data.groupby(by='lyricist').count()['msno'].to_dict()\n",
    "lyricist_rec_cnt[0] = np.nan\n",
    "song['lyricist_rec_cnt'] = song['lyricist'].apply(lambda x: lyricist_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "genre_rec_cnt = data.groupby(by='first_genre_id').count()['msno'].to_dict()\n",
    "genre_rec_cnt[0] = np.nan\n",
    "song['genre_rec_cnt'] = song['first_genre_id'].apply(lambda x: genre_rec_cnt[x] if not np.isnan(x) else np.nan)\n",
    "\n",
    "## msno context features\n",
    "dummy_feat = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "concat = train.drop('target', axis=1)._append(test.drop('id', axis=1))\n",
    "\n",
    "# for feat in dummy_feat:\n",
    "#     feat_dummies = pd.get_dummies(concat[feat])\n",
    "#     feat_dummies.columns = ['msno_%s_'%feat + '%s'%col for col in feat_dummies.columns]\n",
    "#     feat_dummies['msno'] = concat['msno'].values\n",
    "#     feat_dummies = feat_dummies.groupby('msno').mean()\n",
    "#     feat_dummies['msno'] = feat_dummies.index\n",
    "#     member = member.merge(feat_dummies, on='msno', how='left')\n",
    "\n",
    "for feat in dummy_feat:\n",
    "    feat_dummies = pd.get_dummies(concat[feat])\n",
    "    feat_dummies.columns = ['msno_%s_'%feat + '%s'%col for col in feat_dummies.columns]\n",
    "    feat_dummies['msno'] = concat['msno'].values\n",
    "    feat_dummies = feat_dummies.groupby('msno').mean()\n",
    "    feat_dummies['msno_new'] = feat_dummies.index  \n",
    "    feat_dummies.reset_index(drop=True, inplace=True)  \n",
    "    member = member.merge(feat_dummies, left_on='msno', right_on='msno_new', how='left')  \n",
    "\n",
    "train_temp = train.merge(member, on='msno', how='left')\n",
    "test_temp = test.merge(member, on='msno', how='left')\n",
    "\n",
    "train['msno_source_system_tab_prob'] = train_temp[[col for col in train_temp.columns if 'source_system_tab' in col]].apply(lambda x: \\\n",
    "        x['msno_source_system_tab_%d'%x['source_system_tab']], axis=1)\n",
    "test['msno_source_system_tab_prob'] = test_temp[[col for col in test_temp.columns if 'source_system_tab' in col]].apply(lambda x: \\\n",
    "        x['msno_source_system_tab_%d'%x['source_system_tab']], axis=1)\n",
    "\n",
    "train['msno_source_screen_name_prob'] = train_temp[[col for col in train_temp.columns if 'source_screen_name' in col]].apply(lambda x: \\\n",
    "        x['msno_source_screen_name_%d'%x['source_screen_name']], axis=1)\n",
    "test['msno_source_screen_name_prob'] = test_temp[[col for col in test_temp.columns if 'source_screen_name' in col]].apply(lambda x: \\\n",
    "        x['msno_source_screen_name_%d'%x['source_screen_name']], axis=1)\n",
    "\n",
    "train['msno_source_type_prob'] = train_temp[[col for col in train_temp.columns if 'source_type' in col]].apply(lambda x: \\\n",
    "        x['msno_source_type_%d'%x['source_type']], axis=1)\n",
    "test['msno_source_type_prob'] = test_temp[[col for col in test_temp.columns if 'source_type' in col]].apply(lambda x: \\\n",
    "        x['msno_source_type_%d'%x['source_type']], axis=1)\n",
    "\n",
    "## to_csv\n",
    "features = ['msno_rec_cnt']\n",
    "for feat in features:\n",
    "    member[feat] = np.log1p(member[feat])\n",
    "member.to_csv('../temporal_data/members_id_cnt.csv', index=False)\n",
    "\n",
    "features = ['song_length', 'song_rec_cnt', 'artist_song_cnt', 'composer_song_cnt', \\\n",
    "        'lyricist_song_cnt', 'genre_song_cnt', 'artist_rec_cnt', \\\n",
    "        'composer_rec_cnt', 'lyricist_rec_cnt', 'genre_rec_cnt']\n",
    "for feat in features:\n",
    "    song[feat] = np.log1p(song[feat])\n",
    "#song['song_length'] = np.log1p(song['song_length'])\n",
    "song.to_csv('../temporal_data/songs_id_cnt.csv', index=False)\n",
    "\n",
    "train.to_csv('../temporal_data/train_id_cnt.csv', index=False)\n",
    "test.to_csv('../temporal_data/test_id_cnt.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isrc_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## load the data\n",
    "train = pd.read_csv('../temporal_data/train_id.csv')\n",
    "test = pd.read_csv('../temporal_data/test_id.csv')\n",
    "song = pd.read_csv('../temporal_data/songs_id_cnt.csv')\n",
    "\n",
    "data = train[['msno', 'song_id']]._append(test[['msno', 'song_id']])\n",
    "\n",
    "print('Data loaded.')\n",
    "\n",
    "## isrc process\n",
    "isrc = song['isrc']\n",
    "song['cc'] = isrc.str.slice(0, 2)\n",
    "song['xxx'] = isrc.str.slice(2, 5)\n",
    "song['yy'] = isrc.str.slice(5, 7).astype(float)\n",
    "song['yy'] = song['yy'].apply(lambda x: 2000+x if x < 18 else 1900+x)\n",
    "\n",
    "song['cc'] = LabelEncoder().fit_transform(song['cc'])\n",
    "song['xxx'] = LabelEncoder().fit_transform(song['xxx'])\n",
    "song['isrc_missing'] = (song['cc'] == 0) * 1.0\n",
    "\n",
    "## song_cnt\n",
    "song_cc_cnt = song.groupby(by='cc').count()['song_id'].to_dict()\n",
    "song_cc_cnt[0] = None\n",
    "song['cc_song_cnt'] = song['cc'].apply(lambda x: song_cc_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "song_xxx_cnt = song.groupby(by='xxx').count()['song_id'].to_dict()\n",
    "song_xxx_cnt[0] = None\n",
    "song['xxx_song_cnt'] = song['xxx'].apply(lambda x: song_xxx_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "song_yy_cnt = song.groupby(by='yy').count()['song_id'].to_dict()\n",
    "song_yy_cnt[0] = None\n",
    "song['yy_song_cnt'] = song['yy'].apply(lambda x: song_yy_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "data = data.merge(song, on='song_id', how='left')\n",
    "\n",
    "song_cc_cnt = data.groupby(by='cc').count()['msno'].to_dict()\n",
    "song_cc_cnt[0] = None\n",
    "song['cc_rec_cnt'] = song['cc'].apply(lambda x: song_cc_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "song_xxx_cnt = data.groupby(by='xxx').count()['msno'].to_dict()\n",
    "song_xxx_cnt[0] = None\n",
    "song['xxx_rec_cnt'] = song['xxx'].apply(lambda x: song_xxx_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "song_yy_cnt = data.groupby(by='yy').count()['msno'].to_dict()\n",
    "song_yy_cnt[0] = None\n",
    "song['yy_rec_cnt'] = song['yy'].apply(lambda x: song_yy_cnt[x] if not np.isnan(x) else None)\n",
    "\n",
    "## to_csv\n",
    "features = ['cc_song_cnt', 'xxx_song_cnt', 'yy_song_cnt', 'cc_rec_cnt', \\\n",
    "        'xxx_rec_cnt', 'yy_rec_cnt']\n",
    "for feat in features:\n",
    "    song[feat] = np.log1p(song[feat])\n",
    "\n",
    "song.drop(['name', 'isrc'], axis=1, inplace=True)\n",
    "song.to_csv('../temporal_data/songs_id_cnt_isrc.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svd_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9934208\n",
      "[1079.09701569  402.36101388  342.15015604  290.25766789  267.48502621\n",
      "  209.99166484  201.41980994  186.60844183  176.48011044  171.87019751\n",
      "  166.79121794  164.30979427  159.6872633   152.93042253  148.44190296\n",
      "  146.07344883  138.47712124  136.88805245  132.59873434  132.02263033\n",
      "  130.96092559  129.04862187  125.54538462  124.33609337  121.7514836\n",
      "  120.57790438  119.51483604  117.37102969  116.98083352  115.27806765\n",
      "  113.75112337  112.84448524  109.47369206  108.56299432  106.69113104\n",
      "  106.64203013  105.20102045  102.78250425  101.55658569  100.48101846\n",
      "  100.1085423    98.3309683    98.05062556   97.82077495   97.20829481\n",
      "   96.1850887    95.76546976   95.22900134]\n",
      "9934069\n",
      "[1408.36398716  455.73519615  338.21892276  322.67571439  277.07120791\n",
      "  243.03345467  197.06733078  193.43869496  177.60460117  168.79532564\n",
      "  165.20992676  162.26970943  154.00695384  151.47375268  150.00775276\n",
      "  140.89518947]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "## load the data\n",
    "tr = pd.read_csv('../temporal_data/train_id_cnt.csv')\n",
    "te = pd.read_csv('../temporal_data/test_id_cnt.csv')\n",
    "member = pd.read_csv('../temporal_data/members_id_cnt.csv')\n",
    "song = pd.read_csv('../temporal_data/songs_id_cnt_isrc.csv')\n",
    "\n",
    "concat = tr[['msno', 'song_id']]._append(te[['msno', 'song_id']])\n",
    "member_cnt = concat['msno'].max() + 1\n",
    "song_cnt = concat['song_id'].max() + 1\n",
    "artist_cnt = int(song['artist_name'].max() + 1)\n",
    "\n",
    "## svd for user-song pairs\n",
    "n_component = 48\n",
    "\n",
    "print(len(concat))\n",
    "\n",
    "data = np.ones(len(concat))\n",
    "msno = concat['msno'].values\n",
    "song_id = concat['song_id'].values\n",
    "\n",
    "rating = sparse.coo_matrix((data, (msno, song_id)))\n",
    "rating = (rating > 0) * 1.0\n",
    "\n",
    "[u, s, vt] = svds(rating, k=n_component)\n",
    "print(s[::-1])\n",
    "s_song = np.diag(s[::-1])\n",
    "\n",
    "members_topics = pd.DataFrame(u[:, ::-1])\n",
    "members_topics.columns = ['member_component_%d'%i for i in range(n_component)]\n",
    "members_topics['msno'] = range(member_cnt)\n",
    "member = member.merge(members_topics, on='msno', how='right')\n",
    "\n",
    "song_topics = pd.DataFrame(vt.transpose()[:, ::-1])\n",
    "song_topics.columns = ['song_component_%d'%i for i in range(n_component)]\n",
    "song_topics['song_id'] = range(song_cnt)\n",
    "song = song.merge(song_topics, on='song_id', how='right')\n",
    "\n",
    "## svd for user-artist pairs\n",
    "n_component = 16\n",
    "\n",
    "concat = concat.merge(song[['song_id', 'artist_name']], on='song_id', how='left')\n",
    "concat = concat[concat['artist_name'] >= 0]\n",
    "msno = concat['msno'].values\n",
    "artist = concat['artist_name'].values.astype(int)\n",
    "\n",
    "print(len(concat))\n",
    "data = np.ones(len(concat))\n",
    "rating_tmp = sparse.coo_matrix((data, (msno, artist)))\n",
    "\n",
    "rating = np.log1p(rating_tmp) * 0.3 + (rating_tmp > 0) * 1.0\n",
    "\n",
    "[u, s, vt] = svds(rating, k=n_component)\n",
    "print(s[::-1])\n",
    "s_artist = np.diag(s[::-1])\n",
    "\n",
    "members_topics = pd.DataFrame(u[:, ::-1])\n",
    "members_topics.columns = ['member_artist_component_%d'%i for i in range(n_component)]\n",
    "members_topics['msno'] = range(member_cnt)\n",
    "member = member.merge(members_topics, on='msno', how='left')\n",
    "\n",
    "\n",
    "artist_topics = pd.DataFrame(vt.transpose()[:, ::-1])\n",
    "artist_topics.columns = ['artist_component_%d'%i for i in range(n_component)]\n",
    "artist_topics['artist_name'] = range(artist_cnt)\n",
    "song = song.merge(artist_topics, on='artist_name', how='left')\n",
    "\n",
    "## dot features\n",
    "member = member.sort_values(by='msno')\n",
    "song = song.sort_values(by='song_id')\n",
    "\n",
    "mem_cols = ['member_component_%d'%i for i in range(48)]\n",
    "song_cols = ['song_component_%d'%i for i in range(48)]\n",
    "\n",
    "member_embeddings = member[mem_cols].values\n",
    "song_embeddings = song[song_cols].values\n",
    "\n",
    "mem_cols = ['member_artist_component_%d'%i for i in range(16)]\n",
    "song_cols = ['artist_component_%d'%i for i in range(16)]\n",
    "\n",
    "member_artist_embeddings = member[mem_cols].values\n",
    "song_artist_embeddings = song[song_cols].values\n",
    "\n",
    "train_dot = np.zeros((len(tr), 2))\n",
    "test_dot = np.zeros((len(te), 2))\n",
    "\n",
    "for i in range(len(tr)):\n",
    "    msno_idx = tr['msno'].values[i]\n",
    "    song_idx = tr['song_id'].values[i]\n",
    "    \n",
    "    train_dot[i, 0] = np.dot(member_embeddings[msno_idx], np.dot(s_song, song_embeddings[song_idx]))\n",
    "    train_dot[i, 1] = np.dot(member_artist_embeddings[msno_idx], np.dot(s_artist, song_artist_embeddings[song_idx]))\n",
    "\n",
    "for i in range(len(te)):\n",
    "    msno_idx = te['msno'].values[i]\n",
    "    song_idx = te['song_id'].values[i]\n",
    "    \n",
    "    test_dot[i, 0] = np.dot(member_embeddings[msno_idx], np.dot(s_song, song_embeddings[song_idx]))\n",
    "    test_dot[i, 1] = np.dot(member_artist_embeddings[msno_idx], np.dot(s_artist, song_artist_embeddings[song_idx]))\n",
    "\n",
    "tr['song_embeddings_dot'] = train_dot[:, 0]\n",
    "tr['artist_embeddings_dot'] = train_dot[:, 1]\n",
    "\n",
    "te['song_embeddings_dot'] = test_dot[:, 0]\n",
    "te['artist_embeddings_dot'] = test_dot[:, 1]\n",
    "\n",
    "## write to files\n",
    "tr.to_csv('../temporal_data/train_id_cnt_svd.csv', index=False)\n",
    "te.to_csv('../temporal_data/test_id_cnt_svd.csv', index=False)\n",
    "member.to_csv('../temporal_data/members_id_cnt_svd.csv', index=False)\n",
    "song.to_csv('../temporal_data/songs_id_cnt_isrc_svd.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timestamp_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size for 10 done.\n",
      "Window size for 25 done.\n",
      "Window size for 500 done.\n",
      "Window size for 5000 done.\n",
      "Window size for 10000 done.\n",
      "Window size for 50000 done.\n",
      "Till-now count done.\n",
      "Varience done.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "## load the data\n",
    "tr = pd.read_csv('../temporal_data/train_id_cnt_svd.csv')\n",
    "te = pd.read_csv('../temporal_data/test_id_cnt_svd.csv')\n",
    "mem = pd.read_csv('../temporal_data/members_id_cnt_svd.csv')\n",
    "song = pd.read_csv('../temporal_data/songs_id_cnt_isrc_svd.csv')\n",
    "\n",
    "## continous index\n",
    "concat = tr[['msno', 'song_id']]._append(te[['msno', 'song_id']])\n",
    "concat['timestamp'] = range(len(concat))\n",
    "\n",
    "## windows_based count\n",
    "window_sizes = [10, 25, 500, 5000, 10000, 50000]\n",
    "\n",
    "msno_list = concat['msno'].values\n",
    "song_list = concat['song_id'].values\n",
    "\n",
    "def get_window_cnt(values, idx, window_size):\n",
    "    lower = max(0, idx-window_size)\n",
    "    upper = min(len(values), idx+window_size)\n",
    "    return (values[lower:idx] == values[idx]).sum(), (values[idx:upper] == values[idx]).sum()\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    msno_before_cnt = np.zeros(len(concat))\n",
    "    song_before_cnt = np.zeros(len(concat))\n",
    "    msno_after_cnt = np.zeros(len(concat))\n",
    "    song_after_cnt = np.zeros(len(concat))\n",
    "    for i in range(len(concat)):\n",
    "        msno_before_cnt[i], msno_after_cnt[i] = get_window_cnt(msno_list, i, window_size)\n",
    "        song_before_cnt[i], song_after_cnt[i] = get_window_cnt(song_list, i, window_size)\n",
    "    concat['msno_%d_before_cnt'%window_size] = msno_before_cnt\n",
    "    concat['song_%d_before_cnt'%window_size] = song_before_cnt\n",
    "    concat['msno_%d_after_cnt'%window_size] = msno_after_cnt\n",
    "    concat['song_%d_after_cnt'%window_size] = song_after_cnt\n",
    "    \n",
    "    print('Window size for %d done.'%window_size)\n",
    "\n",
    "## till_now count\n",
    "msno_dict = defaultdict(lambda: 0)\n",
    "song_dict = defaultdict(lambda: 0)\n",
    "\n",
    "msno_till_now_cnt = np.zeros(len(concat))\n",
    "song_till_now_cnt = np.zeros(len(concat))\n",
    "for i in range(len(concat)):\n",
    "    msno_till_now_cnt[i] = msno_dict[msno_list[i]]\n",
    "    msno_dict[msno_list[i]] += 1\n",
    "    \n",
    "    song_till_now_cnt[i] = song_dict[song_list[i]]\n",
    "    song_dict[song_list[i]] += 1\n",
    "\n",
    "concat['msno_till_now_cnt'] = msno_till_now_cnt\n",
    "concat['song_till_now_cnt'] = song_till_now_cnt\n",
    "\n",
    "print('Till-now count done.')\n",
    "\n",
    "## varience\n",
    "def timestamp_map(x):\n",
    "    if x < 7377418:\n",
    "        x = (x - 0.0) / (7377417.0 - 0.0) * (1484236800.0 - 1471190400.0) + 1471190400.0\n",
    "    else:\n",
    "        x = (x - 7377417.0) / (9934207.0 - 7377417.0) * (1488211200.0 - 1484236800.0) + 1484236800.0\n",
    "\n",
    "    return x\n",
    "    \n",
    "concat['timestamp'] = concat['timestamp'].apply(timestamp_map)\n",
    "\n",
    "msno_mean = concat.groupby(by='msno').mean()['timestamp'].to_dict()\n",
    "mem['msno_timestamp_mean'] = mem['msno'].apply(lambda x: msno_mean[x])\n",
    "\n",
    "msno_std = concat.groupby(by='msno').std()['timestamp'].to_dict()\n",
    "mem['msno_timestamp_std'] = mem['msno'].apply(lambda x: msno_std[x])\n",
    "\n",
    "song_mean = concat.groupby(by='song_id').mean()['timestamp'].to_dict()\n",
    "song['song_timestamp_mean'] = song['song_id'].apply(lambda x: song_mean[x])\n",
    "\n",
    "song_std = concat.groupby(by='song_id').std()['timestamp'].to_dict()\n",
    "song['song_timestamp_std'] = song['song_id'].apply(lambda x: song_std[x])\n",
    "\n",
    "print('Varience done.')\n",
    "\n",
    "## save to files\n",
    "features = ['msno_till_now_cnt', 'song_till_now_cnt']\n",
    "for window_size in window_sizes:\n",
    "    features += ['msno_%d_before_cnt'%window_size, 'song_%d_before_cnt'%window_size, \\\n",
    "            'msno_%d_after_cnt'%window_size, 'song_%d_after_cnt'%window_size]\n",
    "for feat in features:\n",
    "    concat[feat] = np.log1p(concat[feat])\n",
    "\n",
    "features = ['timestamp'] + features\n",
    "\n",
    "data = concat[features].values\n",
    "for i in range(len(features)):\n",
    "    tr[features[i]] = data[:len(tr), i]\n",
    "    te[features[i]] = data[len(tr):, i]\n",
    "\n",
    "tr.to_csv('../temporal_data/train_id_cnt_svd_stamp.csv', index=False)\n",
    "te.to_csv('../temporal_data/test_id_cnt_svd_stamp.csv', index=False)\n",
    "mem.to_csv('../temporal_data/members_id_cnt_svd_stamp.csv', index=False)\n",
    "song.to_csv('../temporal_data/songs_id_cnt_isrc_svd_stamp.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## before_after_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded.\n",
      "7377418\n",
      "2556790\n",
      "data before done.\n",
      "data after done.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "## load data\n",
    "tr = pd.read_csv('../temporal_data/train_id_cnt_svd_stamp.csv')\n",
    "te = pd.read_csv('../temporal_data/test_id_cnt_svd_stamp.csv')\n",
    "\n",
    "print('data loaded.')\n",
    "print(len(tr))\n",
    "print(len(te))\n",
    "\n",
    "## continous index\n",
    "concat = tr[['msno', 'song_id', 'source_type', 'source_screen_name', 'timestamp']]._append(te[['msno', \\\n",
    "        'song_id', 'source_type', 'source_screen_name', 'timestamp']])\n",
    "\n",
    "## before data\n",
    "song_dict = defaultdict(lambda: None)\n",
    "type_dict = defaultdict(lambda: None)\n",
    "name_dict = defaultdict(lambda: None)\n",
    "time_dict = defaultdict(lambda: None)\n",
    "\n",
    "before_data = np.zeros((len(concat), 4))\n",
    "for i in range(len(concat)):\n",
    "    msno = concat['msno'].values[i]\n",
    "    \n",
    "    if(song_dict[msno] == None):\n",
    "        before_data[i] = concat[['song_id', 'source_type', 'source_screen_name', 'timestamp']].values[i]\n",
    "        before_data[i, 3] = np.nan\n",
    "    else:\n",
    "        before_data[i, 0] = song_dict[msno]\n",
    "        before_data[i, 1] = type_dict[msno]\n",
    "        before_data[i, 2] = name_dict[msno]\n",
    "        before_data[i, 3] = time_dict[msno]\n",
    "\n",
    "    song_dict[msno] = concat['song_id'].values[i]\n",
    "    type_dict[msno] = concat['source_type'].values[i]\n",
    "    name_dict[msno] = concat['source_screen_name'].values[i]\n",
    "    time_dict[msno] = concat['timestamp'].values[i]\n",
    "\n",
    "print('data before done.')\n",
    "\n",
    "## after data\n",
    "song_dict = defaultdict(lambda: None)\n",
    "type_dict = defaultdict(lambda: None)\n",
    "name_dict = defaultdict(lambda: None)\n",
    "time_dict = defaultdict(lambda: None)\n",
    "\n",
    "after_data = np.zeros((len(concat), 4))\n",
    "for i in range(len(concat))[::-1]:\n",
    "    msno = concat['msno'].values[i]\n",
    "    \n",
    "    if(song_dict[msno] == None):\n",
    "        after_data[i] = concat[['song_id', 'source_type', 'source_screen_name', 'timestamp']].values[i]\n",
    "        after_data[i, 3] = np.nan\n",
    "    else:\n",
    "        after_data[i, 0] = song_dict[msno]\n",
    "        after_data[i, 1] = type_dict[msno]\n",
    "        after_data[i, 2] = name_dict[msno]\n",
    "        after_data[i, 3] = time_dict[msno]\n",
    "\n",
    "    song_dict[msno] = concat['song_id'].values[i]\n",
    "    type_dict[msno] = concat['source_type'].values[i]\n",
    "    name_dict[msno] = concat['source_screen_name'].values[i]\n",
    "    time_dict[msno] = concat['timestamp'].values[i]\n",
    "\n",
    "print('data after done.')\n",
    "\n",
    "## to_csv\n",
    "idx = 0\n",
    "for i in ['song_id', 'source_type', 'source_screen_name', 'timestamp']:\n",
    "    tr['before_'+i] = before_data[:len(tr), idx]\n",
    "    tr['after_'+i] = after_data[:len(tr), idx]\n",
    "    \n",
    "    te['before_'+i] = before_data[len(tr):, idx]\n",
    "    te['after_'+i] = after_data[len(tr):, idx]\n",
    "    \n",
    "    idx += 1\n",
    "\n",
    "for i in ['song_id', 'source_type', 'source_screen_name']:\n",
    "    tr['before_'+i] = tr['before_'+i].astype(int)\n",
    "    te['before_'+i] = te['before_'+i].astype(int)\n",
    "    tr['after_'+i] = tr['after_'+i].astype(int)\n",
    "    te['after_'+i] = te['after_'+i].astype(int)\n",
    "\n",
    "tr['before_timestamp'] = np.log1p(tr['timestamp'] - tr['before_timestamp'])\n",
    "te['before_timestamp'] = np.log1p(te['timestamp'] - te['before_timestamp'])\n",
    "\n",
    "tr['after_timestamp'] = np.log1p(tr['after_timestamp'] - tr['timestamp'])\n",
    "te['after_timestamp'] = np.log1p(te['after_timestamp'] - te['timestamp'])\n",
    "\n",
    "tr['before_timestamp'].fillna(np.nanmean(tr['before_timestamp']), inplace=True)\n",
    "te['before_timestamp'].fillna(np.nanmean(te['before_timestamp']), inplace=True)\n",
    "tr['after_timestamp'].fillna(np.nanmean(tr['after_timestamp']), inplace=True)\n",
    "te['after_timestamp'].fillna(np.nanmean(te['after_timestamp']), inplace=True)\n",
    "\n",
    "tr.to_csv('../temporal_data/train_id_cnt_svd_stamp_before_after.csv', index=False)\n",
    "te.to_csv('../temporal_data/test_id_cnt_svd_stamp_before_after.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## load the data\n",
    "train = pd.read_csv('../temporal_data/train_id_cnt_svd_stamp_before_after.csv')\n",
    "test = pd.read_csv('../temporal_data/test_id_cnt_svd_stamp_before_after.csv')\n",
    "member = pd.read_csv('../temporal_data/members_id_cnt_svd_stamp.csv')\n",
    "song = pd.read_csv('../temporal_data/songs_id_cnt_isrc_svd_stamp.csv')\n",
    "\n",
    "## prepare data for train / test\n",
    "train.to_csv('../train.csv', index=False, float_format='%.6f')\n",
    "test.to_csv('../test.csv', index=False, float_format='%.6f')\n",
    "\n",
    "train['iid'] = train['song_id'] * 100000 + train['msno']\n",
    "test['iid'] = test['song_id'] * 100000 + test['msno']\n",
    "\n",
    "iid_set = set(test['iid'].values)\n",
    "train['appeared'] = train['iid'].apply(lambda x: x in iid_set)\n",
    "train = train[train['appeared'] == False]\n",
    "\n",
    "train.drop(['iid', 'appeared'], axis=1, inplace=True)\n",
    "train.to_csv('../train_part.csv', index=False, float_format='%.6f')\n",
    "\n",
    "## prepare data for member / song for GBDT\n",
    "member.to_csv('../members_gbdt.csv', index=False)\n",
    "\n",
    "columns = ['composer', 'lyricist', 'language', 'first_genre_id', 'second_genre_id', 'third_genre_id']\n",
    "for col in columns:\n",
    "    song[col].fillna(0, inplace=True)\n",
    "    song[col] = song[col].astype(int)\n",
    "song['artist_name'].fillna(np.max(song['artist_name'])+1, inplace=True)\n",
    "song['artist_name'] = song['artist_name'].astype(int)\n",
    "song['isrc_missing'] = song['isrc_missing'].astype(int)\n",
    "song.to_csv('../songs_gbdt.csv', index=False)\n",
    "\n",
    "## prepare data for member / song for NN\n",
    "member['bd_missing'] = np.isnan(member['bd'].values) * 1\n",
    "\n",
    "columns = ['bd']\n",
    "for col in columns:\n",
    "    member[col].fillna(np.nanmean(member[col]), inplace=True)\n",
    "\n",
    "member['msno_timestamp_std'].fillna(np.nanmin(member['msno_timestamp_std']), inplace=True)\n",
    "member.to_csv('../members_nn.csv', index=False)\n",
    "\n",
    "song['song_id_missing'] = np.isnan(song['song_length'].values) * 1\n",
    "\n",
    "columns = ['song_length', 'genre_id_cnt', 'artist_song_cnt', 'composer_song_cnt', \\\n",
    "       'lyricist_song_cnt', 'genre_song_cnt', 'song_rec_cnt', \\\n",
    "       'artist_rec_cnt', 'composer_rec_cnt', 'lyricist_rec_cnt', \\\n",
    "       'genre_rec_cnt', 'yy', 'cc_song_cnt', \\\n",
    "       'xxx_song_cnt', 'yy_song_cnt', 'cc_rec_cnt', 'xxx_rec_cnt', \\\n",
    "       'yy_rec_cnt', 'song_timestamp_std', 'artist_cnt', 'lyricist_cnt', \\\n",
    "       'composer_cnt', 'is_featured'] + ['artist_component_%d'%i for i in range(16)]\n",
    "for col in columns:\n",
    "    song[col].fillna(np.nanmean(song[col]), inplace=True)\n",
    "\n",
    "song.to_csv('../songs_nn.csv', index=False)\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tr = pd.read_csv('../train_part.csv')\n",
    "te = pd.read_csv('../test.csv')\n",
    "song = pd.read_csv('../songs_nn.csv')\n",
    "\n",
    "concat = tr[['msno', 'song_id', 'source_system_tab', 'source_screen_name', \\\n",
    "        'source_type']]._append(te[['msno', 'song_id', 'source_system_tab', \\\n",
    "        'source_screen_name', 'source_type']])\n",
    "concat = concat.merge(song[['song_id', 'song_length', 'artist_name', 'first_genre_id', \\\n",
    "        'artist_rec_cnt', 'song_rec_cnt', 'artist_song_cnt', 'xxx', 'yy', \\\n",
    "        'language']], on='song_id', how='left')\n",
    "\n",
    "concat['source'] = concat['source_system_tab'] * 10000 + concat['source_screen_name'] * 100 + \\\n",
    "        concat['source_type']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "concat['source'] = LabelEncoder().fit_transform(concat['source'].values)\n",
    "\n",
    "## member features\n",
    "\n",
    "mem_add = pd.DataFrame({'msno': range(concat['msno'].max()+1)})\n",
    "data_avg = concat[['msno', 'song_length', 'artist_song_cnt', \\\n",
    "        'artist_rec_cnt', 'song_rec_cnt', 'yy']].groupby('msno').mean()\n",
    "data_avg.columns = ['msno_'+i+'_mean' for i in data_avg.columns]\n",
    "data_avg['msno'] = data_avg.index.values\n",
    "data_avg.reset_index(drop=True, inplace=True)\n",
    "mem_add = mem_add.merge(data_avg, on='msno', how='left')\n",
    "\n",
    "data_std = concat[['msno', 'song_length', 'artist_song_cnt', \\\n",
    "        'artist_rec_cnt', 'song_rec_cnt', 'yy']].groupby('msno').std()\n",
    "data_std.columns = ['msno_'+i+'_std' for i in data_std.columns]\n",
    "data_std['msno'] = data_std.index.values\n",
    "data_std.reset_index(drop=True, inplace=True)\n",
    "mem_add = mem_add.merge(data_std, on='msno', how='left')\n",
    "\n",
    "artist_msno = concat[['msno', 'artist_name']].groupby('msno').apply(lambda x: len(set(x['artist_name'].values)))\n",
    "mem_add['artist_msno_cnt'] = artist_msno\n",
    "mem_add['artist_msno_cnt'] = np.log1p(mem_add['artist_msno_cnt'])\n",
    "\n",
    "language_dummy = pd.get_dummies(concat['language'])\n",
    "language_dummy['msno'] = concat['msno'].values\n",
    "language_prob = language_dummy.groupby('msno').mean()\n",
    "language_prob.columns = ['msno_language_%d'%i for i in language_prob.columns]\n",
    "language_prob['msno'] = language_prob.index\n",
    "language_prob.reset_index(drop=True, inplace=True)\n",
    "mem_add = mem_add.merge(language_prob, on='msno', how='left')\n",
    "\n",
    "mem_add.to_csv('../members_add.csv', index=False)\n",
    "\n",
    "## train/test features\n",
    "\n",
    "col = ['artist_name', 'first_genre_id', 'xxx', 'language', 'yy', 'source']\n",
    "for feat in col:\n",
    "    concat['id'] = concat['msno'] * 100000 + concat[feat]\n",
    "    id_cnt = concat[['msno', 'id']].groupby('id').count().to_dict()['msno']\n",
    "    concat['msno_'+feat+'_cnt'] = concat['id'].apply(lambda x: id_cnt[x])\n",
    "\n",
    "msno_cnt = concat[['msno', 'song_id']].groupby('msno').count().to_dict()['song_id']\n",
    "concat['msno_cnt'] = concat['msno'].apply(lambda x: msno_cnt[x])\n",
    "for feat in col:\n",
    "    concat['msno_'+feat+'_prob'] = concat['msno_'+feat+'_cnt'] / concat['msno_cnt']\n",
    "\n",
    "cols = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "for col in cols:\n",
    "    concat['id'] = concat['song_id'] * 10000 + concat[col]\n",
    "    id_cnt = concat[['msno', 'id']].groupby('id').count().to_dict()['msno']\n",
    "    concat['song_'+col+'_cnt'] = concat['id'].apply(lambda x: id_cnt[x])\n",
    "\n",
    "song_cnt = concat[['msno', 'song_id']].groupby('song_id').count().to_dict()['msno']\n",
    "concat['song_cnt'] = concat['song_id'].apply(lambda x: song_cnt[x])\n",
    "\n",
    "for col in cols:\n",
    "    concat['song_'+col+'_prob'] = concat['song_'+col+'_cnt'] / concat['song_cnt']\n",
    "\n",
    "result = concat[['msno_artist_name_prob', 'msno_first_genre_id_prob', 'msno_xxx_prob', \\\n",
    "        'msno_language_prob', 'msno_yy_prob', 'song_source_system_tab_prob', \\\n",
    "        'song_source_screen_name_prob', 'song_source_type_prob', 'source', 'msno_source_prob']]\n",
    "\n",
    "result[:len(tr)].to_csv('../train_part_add.csv', index=False)\n",
    "result[len(tr):].to_csv('../test_add.csv', index=False)\n",
    "print(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs247_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
